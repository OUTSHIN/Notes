 

## `jieba`库

> 优秀的中文分词第三方库（安装：`pip install jieba`）

#### 三种分词模式

1. 精确模式

   > 把文本精确的切分开，不存在冗余单词

2. 全模式

   > 把文本中所有可能的词语都扫描出来，有冗余

3. 搜索引擎模式

   > 在精确模式基础上，对长词再次切分

#### 常用函数

1. `jieba.lcut(s)`

   > 精确模式，返回一个列表类型的分词结果
   >
   > ```python
   > >>>jieba.lcut("中国是一个伟大的国家")
   > ['中国','是','一个','伟大','的','国家']
   > ```

2. `jieba.lcut(s,cut_all=True)`

   > 全模式，返回列表类型的分词结果，存在冗余
   >
   > ```python
   > >>>jieba.lcut("中国是一个伟大的国家")
   > ['中国','国是','一个','伟大','的','国家']
   > ```

3. `jieba.lcut_for_search(s)`

   > 搜索引擎模式，返回一个列表类型的分词结果，存在冗余
   >
   > ```python
   > >>>jieba.lcut_for_search("中华人民共和国是伟大的")
   > ['中华','华人','人民','共和','共和国','中华人民共和国','是','伟大','的’]
   > ```

4. `jieba.add_word(w)`

   > 向分词词典添加新词w

